#pragma once
#ifndef OPINF_LINEARALGEBRA_H
#define OPINF_LINEARALGEBRA_H

#include <cuda_runtime_api.h>
#include <cublasLt.h>
#include <exception>
#include <iostream>
#include <memory>
#include <stdexcept>
#include <string>
#include "CudaLibraries.h"
#include "CudaGpuMatrix.h"
#include "CudaGpuVector.h"
#include "LinearAlgebraKernels.cuh"
#include "utilities.h"

/// <summary>
/// Decomposition of an M x N matrix A
/// </summary>
struct svd
{
	/// <summary>
	/// M x M matrix containing left singular vectors of A
	/// </summary>
	cuda_gpu_matrix U;
	/// <summary>
	/// M x N matrix containing singular values of A on the diagonal
	///		(min(M, N) elements on the diagonal, at most min(M, N) elements)
	/// </summary>
	cuda_gpu_matrix S;
	/// <summary>
	/// N x N matrix containing right singular vectors of A
	/// </summary>
	cuda_gpu_matrix Vt;
};

class linear_algebra
{
public:
	linear_algebra(const cuda_libraries& libraries) : cudalibraries(libraries) {}

	/// <summary>
	/// Computes and returns C where C = (A | transpose(A)) * (B | transpose(B))
	/// </summary>
	/// <param name="A"></param>
	/// <param name="transposeA"></param>
	/// <param name="B"></param>
	/// <param name="transposeB"></param>
	/// <param name="BColumnSubset"></param>
	/// <param name="ans"></param>
	cuda_gpu_matrix multiply(
		const cuda_gpu_matrix& A,
		bool transposeA,
		const cuda_gpu_matrix& B,
		bool transposeB) const;

	/// <summary>
	/// Returns a new vector y = alpha * a + beta * b
	/// </summary>
	cuda_gpu_vector add(
		const cuda_gpu_vector& a,
		double alpha,
		const cuda_gpu_vector& b,
		double beta);

	/// <summary>
	/// returns a new matrix generated by taking a subset of A,
	///	 described by row_range and column_range 
	/// </summary>
	/// <param name="A"></param>
	/// <param name="row_range"></param>
	/// <param name="column_range"></param>
	/// <returns></returns>
	cuda_gpu_matrix subset(
		const cuda_gpu_matrix& A,
		std::pair<size_t, size_t> row_range,
		std::pair<size_t, size_t> column_range) const;

	/// <summary>
	/// If shouldConcatenateVertically is true, concatenates a matrix A of size M x K 
	///	and a matrix B of size N x K into a new matrix of size (M + N) x K
	///	If shouldConcatenateVertically is false, concatenates a matrix A of size M x K
	///	and a matrix B of size M x N into a new matrix of size M x (K + N).
	///	A always comes before B, A is either to the left of, or above B depending on the
	///		parameter shouldConcatenateVertically.
	/// </summary>
	/// <param name="A"></param>
	/// <param name="B"></param>
	/// <param name="shouldConcatenateVertically"></param>
	/// <returns></returns>
	cuda_gpu_matrix concatenate(
		const cuda_gpu_matrix& A,
		const cuda_gpu_matrix& B,
		bool shouldConcatenateVertically) const;

	/// <summary>
	/// Returns A^T
	/// </summary>
	cuda_gpu_matrix transpose(const cuda_gpu_matrix& A) const;

	/// <summary>
	/// Solves the linear regression Ax = b for x with L2/tikhonov regularization penalty k
	/// </summary>
	/// <param name="A"></param>
	/// <param name="b"></param>
	/// <param name="k"></param>
	/// <returns></returns>
	cuda_gpu_matrix tikhonov(const cuda_gpu_matrix& A, const cuda_gpu_matrix& b, double k) const;

	/// <summary>
	/// Performs singular value decomposition, returning the full singular value decomposition
	/// </summary>
	/// <param name="A"></param>
	/// <returns></returns>
	svd svd_decomposition(const cuda_gpu_matrix& A) const;

	/// <summary>
	/// Moore-Penrose pseudoinverse of matrix A
	/// </summary>
	/// <param name="A"></param>
	/// <returns></returns>
	cuda_gpu_matrix pinv(const cuda_gpu_matrix& A) const;

	/// <summary>
	/// Moore-Penrose pseudoinverse of matrix given by the provided
	///		SVDecomposition, that is, returns the pseudoinverse of the matrix
	///		U * S * Vt
	/// </summary>
	/// <param name="A"></param>
	/// <returns></returns>
	cuda_gpu_matrix pinv(const svd& decomposition) const;

	/// <summary>
	/// For an M x K matrix A, get_matrix_squared returns an M x (K * (K + 1) / 2) matrix
	///	  done by taking the product of each column. While the Kroenecker product contains
	///   redundancy, get_matrix_squared does not.
	/// </summary>
	/// <param name="A"></param>
	/// <returns></returns>
	cuda_gpu_matrix get_matrix_squared(const cuda_gpu_matrix& A) const;

	/// <summary>
	/// Returns a vector of length n of all 1's
	/// </summary>
	/// <param name="n"></param>
	/// <returns></returns>
	cuda_gpu_vector get_ones(size_t n) const;

	/// <summary>
	/// Finds the column wise maximums for A. If A is an M x N matrix, then
	///		the answer has dimension 1 x N.
	/// </summary>
	/// <param name="A"></param>
	/// <returns></returns>
	cuda_gpu_matrix find_column_maxes(const cuda_gpu_matrix& A) const;

	/// <summary>
	/// Normalizes each column of the matrix A to fall within the range [-1, 1] and returns 
	///		the corresponding scaling;
	/// </summary>
	/// <param name="A"></param>
	/// <returns></returns>
	void column_normalize(cuda_gpu_matrix& A, const cuda_gpu_matrix& scaling) const;

private:
	const cuda_libraries& cudalibraries;
};

#endif OPINF_LINEARALGEBRA_H
